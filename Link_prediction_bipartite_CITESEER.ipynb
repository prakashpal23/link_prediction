{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1691068845125,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "hFwLefIsTwZL",
    "outputId": "22cf3ed6-8db2-4eb1-8de0-79fa2094f3c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/y756xq8918q0kf1g4nk4vykh0000gn/T/ipykernel_45426/819003294.py:10: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install deeprobust\n",
    "# !conda install pytorch torchvision torchaudio -c pytorch\n",
    "import torch\n",
    "# print(torch.__version__)\n",
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "# !pip install torch-geometric\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "import random\n",
    "from torch.nn import Linear,Sigmoid\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, GraphConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dYuSfuanVdLy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = \"./data\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1691068850937,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "rn5YNSFOog43",
    "outputId": "1fca16bd-63cc-4526-eea0-62469e8159fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kr/y756xq8918q0kf1g4nk4vykh0000gn/T/ipykernel_45426/1785052457.py:7: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "\n",
    "\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "import random\n",
    "\n",
    "from random import sample\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csgraph\n",
    "from scipy.sparse.linalg import inv\n",
    "\n",
    "from scipy.sparse import random\n",
    "from scipy.sparse.linalg import norm\n",
    "\n",
    "from scipy.sparse import random\n",
    "from scipy.stats import rv_continuous\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1tCWvnpupR37"
   },
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cKccKEapUqT4"
   },
   "outputs": [],
   "source": [
    "# from deeprobust.graph.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l0NC0KhdT8JA"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csgraph\n",
    "from scipy.sparse.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1691068850938,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "HdTn8OjSCVDL",
    "outputId": "a05033de-95e6-4240-e7a9-6182cba31d52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/prakashpal/Desktop/Sandip Sir/Cora'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "dataset = os.path.join(os.getcwd(),'Cora')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1691068850938,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "Ch6kq6OxM8Ur",
    "outputId": "69e6664d-a7d4-4bfc-af81-ee62eac38276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "torch.Size([2708, 1433]) torch.Size([2708, 2708])\n",
      "torch.Size([2708, 1433]) torch.Size([2708, 2708])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset= Planetoid(root=dataset, name='Cora')\n",
    "print(dataset[0])\n",
    "adj = to_dense_adj(dataset[0].edge_index)\n",
    "adj = adj[0]\n",
    "labels = dataset[0].y\n",
    "labels = labels.numpy()\n",
    "\n",
    "X = dataset[0].x\n",
    "X = X.to_dense()\n",
    "N = X.shape[0]\n",
    "NO_OF_CLASSES =  len(set(np.array(dataset[0].y)))\n",
    "\n",
    "print(X.shape, adj.shape)\n",
    "\n",
    "nn = int(1*N)\n",
    "X = X[:nn,:]\n",
    "adj = adj[:nn,:nn]\n",
    "labels = labels[:nn]\n",
    "print(X.shape,adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1691068850938,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "3FQJfical415",
    "outputId": "9881634f-a216-4d39-8cba-2dbedbcaa8ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = dataset[0]\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "split = T.RandomLinkSplit(\n",
    "    num_val=0.01,\n",
    "    num_test=0.02,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "tra, va, tes = split(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10242], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[5121], edge_label_index=[2, 5121])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10346], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[210], edge_label_index=[2, 210])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10242], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[104], edge_label_index=[2, 104])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1691068850938,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "STsLjDMMN2bk",
    "outputId": "d5d7ac79-19fe-4203-fcf6-f6e964c2ae64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 2708])\n"
     ]
    }
   ],
   "source": [
    "def get_laplacian(adj):\n",
    "    b=torch.ones(adj.shape[0])\n",
    "    return torch.diag(adj@b)-adj\n",
    "\n",
    "theta = get_laplacian(adj)\n",
    "print(theta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1691068850939,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "BxPj9tu-YZjX",
    "outputId": "b9a12412-89be-4738-ab88-f4357104a7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 1433)\n",
      "7 2708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = X.numpy()\n",
    "NO_OF_NODES = X.shape[0]\n",
    "print(features.shape)\n",
    "print(NO_OF_CLASSES,NO_OF_NODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YiN9k3_MueR-"
   },
   "outputs": [],
   "source": [
    "def convertScipyToTensor(coo):\n",
    "  try:\n",
    "    coo = coo.tocoo()\n",
    "  except:\n",
    "    coo = coo\n",
    "  values = coo.data\n",
    "  indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "  i = torch.LongTensor(indices)\n",
    "  v = torch.FloatTensor(values)\n",
    "  shape = coo.shape\n",
    "\n",
    "  return torch.sparse.FloatTensor(i, v, torch.Size(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Xla8XecUULkS"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import random\n",
    "from scipy.sparse.linalg import norm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "p = X.shape[0]\n",
    "k = int(p*0.5)\n",
    "n = X.shape[1]\n",
    "lambda_param = 100\n",
    "beta_param = 0.1\n",
    "gamma_param = 100\n",
    "lr = 1e-5\n",
    "thresh = 1e-10\n",
    "\n",
    "from scipy.sparse import random\n",
    "from scipy.stats import rv_continuous\n",
    "class CustomDistribution(rv_continuous):\n",
    "    def _rvs(self,  size=None, random_state=None):\n",
    "        return random_state.standard_normal(size)\n",
    "temp = CustomDistribution(seed=1)\n",
    "temp2 = temp()  # get a frozen version of the distribution\n",
    "X_tilde = random(k, n, density=0.25, random_state=1, data_rvs=temp2.rvs)\n",
    "C = random(p, k, density=0.25, random_state=1, data_rvs=temp2.rvs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rnKqrqAS9qmw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(X.shape[1], 64)\n",
    "        self.conv2 = GCNConv(64, NO_OF_CLASSES)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        #print(\"Checking 1: x\", x.shape, \"Edge index:\", edge_index.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        #print(\"Checking 2: convolution done, new x:\", x.shape)\n",
    "        x = F.relu(x)\n",
    "        #print(\"Checking 3: x\", x.shape, \"training:\", self.training)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #print(\"Checking 4: dropout done new x\", x.shape, \"Edge index:\", edge_index.shape)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        #print(\"Checking 5: x\", x.shape)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1691068851910,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "KI0vNiT4CVDO",
    "outputId": "4f2e37bd-ab2e-44af-c168-8dfd4c9f1939"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2708, 1433)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PmoeVIS3HErX"
   },
   "outputs": [],
   "source": [
    "def feature(feat):\n",
    "  graph = feat\n",
    "  print(\"feat:\",graph)\n",
    "  print(\"------------------\",type(feat))\n",
    "  # type(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1691068851911,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "GrHgN-_mCVDP",
    "outputId": "c6470491-5fdc-45e2-d9d3-4cf4e2c01a01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 1433])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FWUuK7-TjIq_"
   },
   "outputs": [],
   "source": [
    "def experiment_structure(alpha_param,lambda_param,beta_param,gamma_param,C,theta,X,A):\n",
    "      p = X.shape[0]\n",
    "      k = int(p*0.5)\n",
    "      n = X.shape[1]\n",
    "      ones = csr_matrix(np.ones((k,k)))\n",
    "      ones = convertScipyToTensor(ones).cuda()\n",
    "      ones = ones.to_dense()\n",
    "      \n",
    "      try:\n",
    "        C = convertScipyToTensor(C)\n",
    "        C = C.to_dense()\n",
    "      except:\n",
    "        C=C\n",
    "      try:\n",
    "        theta = convertScipyToTensor(theta)\n",
    "      except:\n",
    "        theta = theta\n",
    "      try:\n",
    "        X = convertScipyToTensor(X)\n",
    "        X = X.to_dense()\n",
    "      except:\n",
    "        X = X\n",
    "      if(torch.cuda.is_available()):\n",
    "        print(\"GPU is available\")\n",
    "        C = C.cuda()\n",
    "        theta = theta.cuda()\n",
    "        X = X.cuda()\n",
    "        ones = ones.cuda()\n",
    "      \n",
    "        \n",
    "      def bracket_term2fun(C,CT,theta):\n",
    "          # U  = update_U(C,theta).double()\n",
    "          U = torch.stack(update_U(C, theta)).double()\n",
    "          UT= torch.transpose(U,0,1)\n",
    "          Lw = (CT @theta @C).double()\n",
    "          lb= 1e-5\n",
    "          ub = 1e+4\n",
    "          beta = 0.5 \n",
    "          lambda_ =  laplacian_lambda_update(lb, ub, beta, U, Lw, k_,C)   \n",
    "          lambda_matrix =  torch.diag(lambda_,0).cuda()\n",
    "#           print(\"U size\",U.size())\n",
    "          return U@lambda_matrix@UT\n",
    "        \n",
    "      def update_U(C,theta):\n",
    "            \n",
    "        CT= torch.transpose(C,0,1)\n",
    "        product = CT @ theta @ C\n",
    "        matrix = torch.tensor(product)  \n",
    "        eigenvalues, eigenvectors = torch.linalg.eig(product)\n",
    "\n",
    "        # select non-zero eigenvalues and eigenvectors\n",
    "        non_zero_eigenvalues = []\n",
    "        non_zero_eigenvectors = []\n",
    "        for i in range(matrix.shape[0]):\n",
    "            if matrix[i, i] != 0:\n",
    "                non_zero_eigenvalues.append(eigenvalues[i])\n",
    "                non_zero_eigenvectors.append(eigenvectors[:, i])\n",
    "        U = [torch.tensor(eigenvector) for eigenvector in non_zero_eigenvectors]\n",
    "        return U    \n",
    " \n",
    "\n",
    "      def update_C(C):\n",
    "          CT = torch.transpose(C,0,1)\n",
    "          C.size()\n",
    "          t1 = alpha_param*(C@ones).cuda()\n",
    "          bracket_term1 = (CT@theta@C).cuda()\n",
    "          bracket_term2 = bracket_term2fun(C,CT,theta) \n",
    "          bracket_term = bracket_term1 - bracket_term2   # bracket term (CT*theta*C - U*lambda*UT)\n",
    "          t22 = -2*(theta@C).cuda() \n",
    "#           print(t22.type())\n",
    "          t3 = bracket_term1\n",
    "          t7 = bracket_term2\n",
    "          t6 = (CT@A@C).cuda()\n",
    "          t5 = 2* beta_param*(A@C)\n",
    "          t5 = t5.float()\n",
    "          t4 = (1.0/k)\n",
    "          t44 = t4*((torch.ones(k,k)).double()).cuda()\n",
    "#           print(t3.device)\n",
    "#           print(t44.device)\n",
    "          t8 = (t3 + t44).cuda()\n",
    "          t9 = torch.pinverse(t8)                  #change it\n",
    "          t9 = t9.float()\n",
    "#           print(t9.type())\n",
    "#           print(t9)\n",
    "          t10 = (t22@t9).cuda()\n",
    "          t11 = (t6 - t7).cuda()\n",
    "          t11 = t11.float()\n",
    "          t12 = (t5@t11)\n",
    "          t13 = (t1 + t10 +t12).cuda()\n",
    "        \n",
    "          #t2 = beta_param*(theta@C@bracket_term.float())\n",
    "          grad_fc= t13\n",
    "          C_new=C-gamma_param*grad_fc\n",
    "          C_new[C_new<thresh] = thresh\n",
    "          for i in range(len(C_new)):\n",
    "              C_new[i] = C_new[i]/torch.linalg.norm(C_new[i],1)\n",
    "          return C_new        \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "      #We set c1 = 10âˆ’5 and c2 = 10^4 We observed that the experimental performances of the algorithms \n",
    "       #are not sensitive to different values of c1 and c2 as long as they are reasonably small and large,respectively\n",
    "      # K is the number of smallest eigenvalues of the Laplacian matrix that are being ignored while updating the eigenvalues.\n",
    "      def laplacian_lambda_update(lb, ub, beta, U, Lw, k, C):\n",
    "        q = Lw.size(1) - k\n",
    "        U = U.cuda()\n",
    "        UT= torch.transpose(U,0,1)\n",
    "        UT = UT.type(torch.float64)\n",
    "        UT = UT.cuda()\n",
    "        \n",
    "        CT= torch.transpose(C,0,1)\n",
    "        CT = CT.type(torch.float64)\n",
    "        CT = CT.cuda()\n",
    "        \n",
    "        AC=(A@C).double()\n",
    "        AC = AC.cuda()\n",
    "        \n",
    "        Af=(CT@AC).double()\n",
    "        Af = Af.cuda()\n",
    "        Af.device\n",
    "        U.device\n",
    "        dd = U@Af@UT\n",
    "        \n",
    "        product = dd\n",
    "        matrix = torch.tensor(product)            \n",
    "\n",
    "        non_zero_diag_elements = []\n",
    "        for i in range(matrix.shape[0]):\n",
    "            if matrix[i, i] != 0:\n",
    "                non_zero_diag_elements.append(matrix[i, i])\n",
    "            if len(non_zero_diag_elements) == len(matrix):\n",
    "                break\n",
    "\n",
    "        k = len(non_zero_diag_elements)\n",
    "        d = torch.diag(torch.tensor(non_zero_diag_elements))\n",
    "\n",
    "       \n",
    "        lambda_ = 0.5 * (d + torch.sqrt(d.pow(2) + 4 / beta))\n",
    "#         print(lambda_)\n",
    "        lambda_,indices = torch.sort(lambda_, dim=- 1, descending=True)\n",
    "        eps = 1\n",
    "        condition = torch.stack([(lambda_[q] - ub) <= eps,\n",
    "                         (lambda_[0] - lb) >= -eps]).all(dim=0)\n",
    "\n",
    "#                                   (lambda_[1:(q)] - lambda_[0:(q-1)]) >= -eps])\n",
    "        if condition.all():\n",
    "            return lambda_\n",
    "        else:\n",
    "            greater_ub = lambda_ > ub\n",
    "            lesser_lb = lambda_ < lb\n",
    "            lambda_[greater_ub] = ub\n",
    "            lambda_[lesser_lb] = lb\n",
    "            condition = torch.stack([(lambda_[q] - ub) <= eps,\n",
    "                         (lambda_[0] - lb) >= -eps]).all(dim=0)\n",
    "\n",
    "#                                   (lambda_[1:q] - lambda_[0:(q-1)]) >= -eps])\n",
    "            if condition.all():\n",
    "                return lambda_\n",
    "            else:\n",
    "#                 print(lambda_)\n",
    "                raise ValueError(\"eigenvalues are not in increasing order, consider increasing the value of beta\")\n",
    "            \n",
    "\n",
    "      for i in tqdm(range(10)): #update C only 21\n",
    "         C = update_C(C)\n",
    "\n",
    "      feat = torch.linalg.pinv(C)@X\n",
    "      print(\"shape of feat\", feat.shape)      \n",
    "      return feat,C\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-1JM_ainCVDP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "class Net1(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
    "            dim=-1\n",
    "        )  # product of a pair of nodes on each edge\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "def train_link_predictor(\n",
    "    model, train_data, val_data, optimizer, criterion, n_epochs=300\n",
    "):\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "        # sampling training negatives for every training epoch\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "            num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "        edge_label_index = torch.cat(\n",
    "            [train_data.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        )\n",
    "        edge_label = torch.cat([\n",
    "            train_data.edge_label,\n",
    "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim=0)\n",
    "\n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_auc = eval_link_predictor(model, val_data)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_link_predictor(model, data):\n",
    "\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_index_coarsen(C_n,theta,labels,graph):\n",
    "    from torch_geometric.data import Data\n",
    "    C_n =C_n.detach().cpu()\n",
    "    theta = theta.detach().cpu()\n",
    "    L_c= C_n.T@theta@C_n\n",
    "    from scipy.sparse import csr_matrix\n",
    "    Wc=(-1*L_c)*(1-np.eye(L_c.shape[0]))\n",
    "    Wc[Wc<0.01]=0\n",
    "    Wc= csr_matrix(Wc)\n",
    "    Wc = Wc.tocoo()\n",
    "    row = torch.from_numpy(Wc.row).to(torch.long)\n",
    "    col = torch.from_numpy(Wc.col).to(torch.long)\n",
    "    edge_index_coarsen2 = torch.stack([row, col], dim=0)\n",
    "#     print(\"Edge_index_coarsen Shape\", edge_index_coarsen2.shape)\n",
    "    return edge_index_coarsen2.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction_auc(C_n,theta,labels,graph):\n",
    "    from torch_geometric.data import Data\n",
    "    C_n =C_n.detach().cpu()\n",
    "    theta = theta.detach().cpu()\n",
    "    L_c= C_n.T@theta@C_n\n",
    "    from scipy.sparse import csr_matrix\n",
    "    Wc=(-1*L_c)*(1-np.eye(L_c.shape[0]))\n",
    "    Wc[Wc<0.001]=0\n",
    "    Wc= csr_matrix(Wc)\n",
    "    Wc = Wc.tocoo()\n",
    "    row = torch.from_numpy(Wc.row).to(torch.long)\n",
    "    col = torch.from_numpy(Wc.col).to(torch.long)\n",
    "    edge_index_coarsen2 = torch.stack([row, col], dim=0)\n",
    "    print(\"Edge_index_coarsen Shape\", edge_index_coarsen2.shape)\n",
    "    \n",
    "        \n",
    "    edge_weight = torch.from_numpy(Wc.data)\n",
    "    def one_hot(x, class_count):\n",
    "        return torch.eye(class_count)[x, :]\n",
    "\n",
    "    Y = labels\n",
    "    Y = one_hot(Y,NO_OF_CLASSES)\n",
    "    P=np.linalg.pinv(C_n)\n",
    "    labels_coarse = torch.argmax(torch.sparse.mm(torch.Tensor(P).double() , Y.double()).double() , 1)\n",
    "    data =Data(x=graph , edge_index= edge_index_coarsen2, y=labels_coarse)\n",
    "    graph = data\n",
    "    import torch_geometric.transforms as T\n",
    "\n",
    "    split = T.RandomLinkSplit(\n",
    "        num_val=0.01,\n",
    "        num_test=0,\n",
    "        is_undirected=True,\n",
    "        add_negative_train_samples=False,\n",
    "        neg_sampling_ratio=1.0,\n",
    "    )\n",
    "    train_data, val_data, test_data = split(graph)\n",
    "    train_data = train_data.cpu()\n",
    "    test_data = test_data.cpu()\n",
    "    val_data = val_data.cpu()\n",
    "\n",
    "    test_data=tes\n",
    "    model = Net1(dataset.num_features, 128, 64)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    model = train_link_predictor(model, train_data, val_data, optimizer, criterion)\n",
    "\n",
    "    test_auc = eval_link_predictor(model, test_data)\n",
    "    print(f\"Test: {test_auc:.3f}\")\n",
    "    acc = test_auc*100\n",
    "    acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2777,
     "status": "ok",
     "timestamp": 1691069227933,
     "user": {
      "displayName": "prakash pal",
      "userId": "12604158459377079954"
     },
     "user_tz": -330
    },
    "id": "kCfwsH_sCVDP",
    "outputId": "140d1bda-883d-470a-e12c-7a1ef1b3bf3d"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m beta_param \u001b[39min\u001b[39;00m [\u001b[39m0.001\u001b[39m,\u001b[39m0.01\u001b[39m,\u001b[39m0.1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m100\u001b[39m]:\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m gamma_param \u001b[39min\u001b[39;00m [\u001b[39m100\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0.1\u001b[39m,\u001b[39m0.01\u001b[39m,\u001b[39m0.001\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m       feat_reduced,C_tilde \u001b[39m=\u001b[39m experiment_structure(alpha_param,lambda_param,beta_param,gamma_param,C,theta,X,adj)\n\u001b[1;32m      7\u001b[0m       edge_index_c\u001b[39m=\u001b[39m edge_index_coarsen(C_tilde,theta,labels,feat_reduced)\n\u001b[1;32m      8\u001b[0m       \u001b[39mprint\u001b[39m(edge_index_c)\n",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m, in \u001b[0;36mexperiment_structure\u001b[0;34m(alpha_param, lambda_param, beta_param, gamma_param, C, theta, X, A)\u001b[0m\n\u001b[1;32m      4\u001b[0m n \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m ones \u001b[39m=\u001b[39m csr_matrix(np\u001b[39m.\u001b[39mones((k,k)))\n\u001b[0;32m----> 6\u001b[0m ones \u001b[39m=\u001b[39m convertScipyToTensor(ones)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      7\u001b[0m ones \u001b[39m=\u001b[39m ones\u001b[39m.\u001b[39mto_dense()\n\u001b[1;32m      9\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\n",
    "highest_accuracy=0\n",
    "lambda_param =0.001\n",
    "for alpha_param in [100,10,1,0.1,0.01,0.001]:\n",
    "  for beta_param in [0.001,0.01,0.1,1,10,100]:\n",
    "      for gamma_param in [100,10,1,0.1,0.01,0.001]:\n",
    "        feat_reduced,C_tilde = experiment_structure(alpha_param,lambda_param,beta_param,gamma_param,C,theta,X,adj)\n",
    "        edge_index_c= edge_index_coarsen(C_tilde,theta,labels,feat_reduced)\n",
    "        print(edge_index_c)\n",
    "        if edge_index_c >500:\n",
    "            link_prediction_auc(C_tilde,theta,labels,feat_reduced)\n",
    "        else:    \n",
    "            print(\"breaking\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STI5wNRYlcsX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNbV7vRylqyg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c1f741a4f83aa020b4b2a4d7353a073a4e5e4a855a3258a20da40294ddbf005"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
